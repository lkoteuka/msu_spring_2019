{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from html.parser import HTMLParser\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import random\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**С помощью selenium выгрузим все book_id всех авторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for mac64 chromedriver:2.46 in cache\n",
      "Driver found in /Users/koteuka/.wdm/chromedriver/2.46/mac64/chromedriver\n",
      "954\n",
      "1091\n",
      "1368\n",
      "1480\n",
      "1774\n"
     ]
    }
   ],
   "source": [
    "def random_sleep(offset=1.5, length=4):\n",
    "    sleep(random.random() * length + offset)\n",
    "\n",
    "author_id = {\n",
    "  \"Дарья Донцова\":  29369,\n",
    "  \"Джеймс Роллинс\": 29442,\n",
    "  \"Макс Фрай\":      102994,\n",
    "  \"Эрин Хантер\":    26149,\n",
    "  \"Дмитрий Емец\":   35952\n",
    "}\n",
    "\n",
    "author_books = []\n",
    "\n",
    "with webdriver.Chrome(ChromeDriverManager().install()) as driver:\n",
    "    for name in author_id:\n",
    "        driver.get(\"https://www.bookvoed.ru/author/books?id={author_id}\".format(author_id=author_id[name]))\n",
    "        random_sleep()\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "        #scroll down while not end of page\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            random_sleep()\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                random_sleep()\n",
    "                try:\n",
    "                    driver.execute_script(\"window.scrollTo(0, {scr});\".format(scr=driver.execute_script(\"return document.body.scrollHeight\")-1000))\n",
    "                    random_sleep()\n",
    "                    elem = driver.find_element_by_xpath('//*[@id=\"author_books_list\"]/div[12]/div[2]/a')\n",
    "                except NoSuchElementException:\n",
    "                    break\n",
    "                elem.click()\n",
    "                random_sleep()\n",
    "            last_height = new_height\n",
    "\n",
    "        #find all book id\n",
    "        items = driver.find_elements_by_class_name(\"gf\")\n",
    "        \n",
    "        #add books id to authors\n",
    "        for item in items:\n",
    "            classes = item.get_attribute('class').split()\n",
    "            author_books.append(item.get_attribute(\"data-book\"))\n",
    "        \n",
    "        print(len(author_books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция для multiprocessing.pool, обрабатывает book_id и возвращает словарь book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the author_books_in_detail \n",
    "def multi_parsing(book_id):\n",
    "    #Get the 'soup'\n",
    "    book_url = \"https://www.bookvoed.ru/book?id={id}\".format(id=book_id)\n",
    "    book_html = requests.get(book_url).text\n",
    "    soup = BeautifulSoup(book_html, 'html.parser')\n",
    "\n",
    "    #def RE for deleting \\n and spaces at the beginning and at the end of the str\n",
    "    def del_n_and_spaces(mystr):\n",
    "        buf = re.sub(\"^\\s+|\\n|\\r|\\s+$\", '', mystr)\n",
    "        return buf if len(buf) > 0 else None\n",
    "\n",
    "    #def for check correct of CSS object\n",
    "    def check(obj):\n",
    "        if obj is not None:\n",
    "            if obj is list:\n",
    "                if len(obj) > 0:\n",
    "                    return obj\n",
    "                else:\n",
    "                    return None\n",
    "            return obj\n",
    "        return None\n",
    "\n",
    "    #def for correct rating of book\n",
    "    def check_rating(book):\n",
    "        if len(re.findall(\"\\d+\\.\\d+\", book['style'])) != 0:\n",
    "            return re.findall(\"\\d+\\.\\d+\", book['style'])[0]\n",
    "        if len(re.findall(\"\\d+\", book['style'])) != 0:\n",
    "            return re.findall(\"\\d+\", book['style'])[0]\n",
    "        \n",
    "    #Correct parse the table\n",
    "    data = []\n",
    "    table = soup.find('table', class_='tw')\n",
    "    for row in table.findAll('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([del_n_and_spaces(ele) for ele in cols if ele])\n",
    "\n",
    "    #Get age rating\n",
    "    age_rating = ''\n",
    "    if soup.find('div', class_='ov nM') is not None:\n",
    "        age_rating = \"0+\"\n",
    "    elif soup.find('div', class_='pv nM') is not None:\n",
    "        age_rating = \"6+\"\n",
    "    elif soup.find('div', class_='qv nM') is not None:\n",
    "        age_rating = \"12+\"\n",
    "    elif soup.find('div', class_='rv nM') is not None:\n",
    "        age_rating = \"16+\"\n",
    "    elif soup.find('div', class_='sv nM') is not None:\n",
    "        age_rating = \"18+\"\n",
    "\n",
    "    #list to dict for correct None placement\n",
    "    data = {re.sub(\"^\\s+|:|\\s+$\", '', data[i][0]): data[i][1] for i in range(len(data))}\n",
    "\n",
    "    #Please don't ask questions, it works -> everything is fine\n",
    "    book = {\n",
    "       \"ID\": book_id,\n",
    "       \"Название\": del_n_and_spaces(soup.find('h1', attrs={'itemprop' : \"name\"}).contents[0]) if check(soup.find('h1', attrs={'itemprop' : \"name\"}))is not None else None,\n",
    "       \"Обложка\": del_n_and_spaces(soup.find('a', class_='sf ee').img['src']) if check(soup.find('a', class_='sf ee')) is not None else None,\n",
    "       \"Возраст\": age_rating,\n",
    "       \"Описание\": del_n_and_spaces(soup.find('div', class_='lw').contents[0]) if check(soup.find('div', class_='lw')) is not None else None,\n",
    "       \"Рейтинг\": check_rating(soup.find('div', class_='af')) if check(soup.find('div', class_='af')) is not None else None,\n",
    "       \"Понравилось\": del_n_and_spaces(soup.find('a', class_='Ke Me ').text) if check(soup.find('a', class_='Ke Me ')) is not None else \"0\",\n",
    "       \"В закладки\": del_n_and_spaces(soup.find('a', class_='Ke Le ff').text) if check(soup.find('a', class_='Ke Le ff')) is not None else \"0\",\n",
    "       \"Не понравилось\": del_n_and_spaces(soup.find('a', class_='Ke Oe ').text) if check(soup.find('a', class_='Ke Oe ')) is not None else \"0\",\n",
    "       \"Цена\": del_n_and_spaces(soup.find('div', class_='Hu Wu').text) if check(soup.find('div', class_='Hu Wu')) is not None else None,\n",
    "       \"Серия\": data['Серия'] if 'Серия' in data else None,\n",
    "       \"Издательство\": data['Издательство'] if 'Издательство' in data else None,\n",
    "       \"Год\": data['Год'] if 'Год' in data else None,\n",
    "       \"Страниц\": data['Страниц'] if 'Страниц' in data else None,\n",
    "       \"Переплёт\": data['Переплёт'] if 'Переплёт' in data else None,\n",
    "       \"ISBN\": data['ISBN'] if 'ISBN' in data else None,\n",
    "       \"Размеры\": data['Размеры'] if 'Размеры' in data else None,\n",
    "       \"Формат\": data['Формат'] if 'Формат' in data else None,\n",
    "       \"Код\": data['Код'] if 'Код' in data else None,\n",
    "       \"В базе\": data['В базе'] if 'В базе' in data else None,\n",
    "       \"Автор\": soup.find('span', class_=\"Av\").text,\n",
    "       \"Тематика\": data['Тематика'] if 'Тематика' in data else None,\n",
    "       \"Тираж\": data['Тираж'] if 'Тираж' in data else None\n",
    "    }\n",
    "    \n",
    "    return book\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Распараллелим нахождение list of books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770 objects are processed..."
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Lock, Value\n",
    "from time import sleep\n",
    "\n",
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "books = []\n",
    "\n",
    "def func_wrapper(uid):\n",
    "    res = multi_parsing(uid) \n",
    "    with mutex:\n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return res\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    books = pool.map(func_wrapper, author_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/koteuka/Desktop/Names.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-577d4e121eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I/O error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/Users/koteuka/Desktop/Names.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/koteuka/Desktop/Names.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "template = {\n",
    "   \"ID\": 6299459,\n",
    "   \"Название\": \"Макс Фрай(ХроникиЕхо)-1.Чуб земли\",\n",
    "   \"Обложка\": \"/files/1836/64/31/10/7.jpeg\",\n",
    "   \"Возраст\": \"16+\",\n",
    "   \"Описание\": \"Трактир \\\"Кофейная гуща\\\" стоит на границе...\",\n",
    "   \"Рейтинг\": 98.7,\n",
    "   \"Понравилось\": 910,\n",
    "   \"В закладки\": 275,\n",
    "   \"Не понравилось\": 12,\n",
    "   \"Цена\": 405.0,\n",
    "   \"Серия\": \"Хроники Ехо\",\n",
    "   \"Издательство\": \"АСТ\",\n",
    "   \"Год\": 2015,\n",
    "   \"Страниц\": 320,\n",
    "   \"Переплёт\": \"твердый\",\n",
    "   \"ISBN\": \"978-5-17-090543-0\",\n",
    "   \"Размеры\": \"13,00 см x 20,00 см x 2,00 см\",\n",
    "   \"Формат\": \"206.00mm x 130.00mm x 18.00mm\",\n",
    "   \"Код\": 1204921,\n",
    "   \"В базе\": \"Макс Фрай(ХроникиЕхо)-1.Чуб земли\",\n",
    "   \"Автор\": \"Фрай Макс\",\n",
    "   \"Тематика\": \"Отечественная\",\n",
    "   \"Тираж\": 5000\n",
    "}\n",
    "\n",
    "csv_file = \"Names.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=template.keys())\n",
    "        writer.writeheader()\n",
    "        for i in range(200):\n",
    "            writer.writerow(books[i])\n",
    "except IOError:\n",
    "    print(\"I/O error\") \n",
    "    \n",
    "ds = pd.read_csv(r\"/Users/koteuka/Desktop/Names.csv\", ',')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
